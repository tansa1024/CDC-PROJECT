{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "153289db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        # Handle both string paths and DataFrames\n",
    "        self.data = pd.read_csv(csv_file) if isinstance(csv_file, str) else csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tab_features = torch.tensor(row.drop(['id', 'price_log'], errors='ignore').values, dtype=torch.float32)\n",
    "        label = torch.tensor(row['price_log'], dtype=torch.float32)\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, f\"{int(row['id'])}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, tab_features, label\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Standard size for ResNet\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce4ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, num_tabular_cols):\n",
    "        super(PricePredictor, self).__init__()\n",
    "        self.resnet = models.resnet18(weights='DEFAULT')\n",
    "        \n",
    "        # UNFREEZE: Allow the CNN to learn from your images\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.vision_features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.tabular_branch = nn.Sequential(\n",
    "            nn.Linear(num_tabular_cols, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(512 + 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        v_feat = self.vision_features(img).view(img.size(0), -1)\n",
    "        t_feat = self.tabular_branch(tab)\n",
    "        combined = torch.cat((v_feat, t_feat), dim=1)\n",
    "        return self.regressor(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6981bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded. Using 17 features.\n",
      "Ready to train on cuda!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Load Scaler\n",
    "scaler = joblib.load('data/scaler.pkl')\n",
    "num_features = len(scaler.feature_names_in_)\n",
    "print(f\"Scaler loaded. Using {num_features} features.\")\n",
    "\n",
    "# 2. Setup DataLoaders\n",
    "train_dataset = MultimodalDataset('data/processed_train.csv', 'house_images', image_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 3. Initialize Model (Only once!)\n",
    "model = PricePredictor(num_tabular_cols=num_features)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 4. Optimizer - Using Adam with the 0.0001 rate that worked\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "print(f\"Ready to train on {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b952b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 803/803 [04:37<00:00,  2.89it/s, loss=0.282] \n",
      "Epoch 2/5: 100%|██████████| 803/803 [01:50<00:00,  7.24it/s, loss=0.00232]\n",
      "Epoch 3/5: 100%|██████████| 803/803 [03:12<00:00,  4.17it/s, loss=0.231] \n",
      "Epoch 4/5: 100%|██████████| 803/803 [03:47<00:00,  3.53it/s, loss=0.269] \n",
      "Epoch 5/5: 100%|██████████| 803/803 [01:40<00:00,  8.03it/s, loss=0.0285] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished. Avg Loss: 0.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5 # Start with 5, as this gave you the 0.75 result before\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for images, tabular, labels in loop:\n",
    "        images, tabular, labels = images.to(device), tabular.to(device), labels.to(device).view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, tabular)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "print(f\"Epoch {epoch+1} finished. Avg Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d9593db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loader defined with 3209 houses!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the test CSV created in the Preprocessing Notebook\n",
    "test_df = pd.read_csv('data/processed_test.csv')\n",
    "\n",
    "# 2. Create the Dataset object\n",
    "test_dataset = MultimodalDataset(\n",
    "    csv_file=test_df, \n",
    "    img_dir='house_images', \n",
    "    transform=image_transforms\n",
    ")\n",
    "\n",
    "# 3. Create the Loader\n",
    "# shuffle=False ensures we can match predictions to the right House IDs\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Test Loader defined with {len(test_df)} houses!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a25578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Evaluation: 100%|██████████| 201/201 [00:28<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! all_preds and all_actuals are now filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set model to 'testing' mode\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "with torch.no_grad(): # Saves memory by not calculating gradients\n",
    "    for images, tabular, labels in tqdm(test_loader, desc=\"Final Evaluation\"):\n",
    "        images, tabular = images.to(device), tabular.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(images, tabular)\n",
    "        \n",
    "        # 1. Move to CPU \n",
    "        # 2. Reverse the Log (np.expm1) to get real dollar values\n",
    "        all_preds.extend(np.expm1(outputs.cpu().numpy()).flatten())\n",
    "        all_actuals.extend(np.expm1(labels.numpy()).flatten())\n",
    "\n",
    "print(\"Done! all_preds and all_actuals are now filled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "654e5628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MODEL EVALUATION ---\n",
      "R2 Score: 0.7685\n",
      "RMSE: $164,563.46\n",
      "MAE:  $101,772.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 1. Convert lists to numpy arrays\n",
    "preds_array = np.array(all_preds)\n",
    "actuals_array = np.array(all_actuals)\n",
    "\n",
    "# 2. Calculate R2 Score (How much variance you explained)\n",
    "r2 = r2_score(actuals_array, preds_array)\n",
    "\n",
    "# 3. Calculate RMSE (Root Mean Squared Error)\n",
    "# This shows the dollar error, penalizing big misses more heavily\n",
    "rmse = np.sqrt(mean_squared_error(actuals_array, preds_array))\n",
    "\n",
    "# 4. Calculate MAE (Mean Absolute Error) for comparison\n",
    "mae = np.mean(np.abs(preds_array - actuals_array))\n",
    "\n",
    "print(f\"--- MODEL EVALUATION ---\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: ${rmse:,.2f}\")\n",
    "print(f\"MAE:  ${mae:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e2f88f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Error: $1,718,025.25\n",
      "R2 for houses under $1.5M: 0.7098\n"
     ]
    }
   ],
   "source": [
    "# Look at your biggest mistakes\n",
    "errors = np.abs(np.array(all_actuals) - np.array(all_preds))\n",
    "print(f\"Max Error: ${np.max(errors):,.2f}\")\n",
    "\n",
    "# Calculate R2 if we ignore houses over $1.5M\n",
    "mask = np.array(all_actuals) < 1500000\n",
    "print(f\"R2 for houses under $1.5M: {r2_score(np.array(all_actuals)[mask], np.array(all_preds)[mask]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4446beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TABULAR ONLY PERFORMANCE ---\n",
      "R2 Score: 0.8961\n",
      "RMSE: $110,245.46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# 1. Load Data\n",
    "train_df = pd.read_csv('data/processed_train.csv')\n",
    "test_df = pd.read_csv('data/processed_test.csv')\n",
    "\n",
    "# 2. Prepare Features (Exclude ID and Target)\n",
    "# Only use the features your scaler knows about\n",
    "scaler = joblib.load('data/scaler.pkl')\n",
    "features = scaler.feature_names_in_\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['price_log']\n",
    "X_test = test_df[features]\n",
    "y_test = test_df['price_log']\n",
    "\n",
    "# 3. Train Tabular-Only Model (XGBoost)\n",
    "tab_model = XGBRegressor(\n",
    "    n_estimators=1000,     # Increase from 100 for deeper learning\n",
    "    learning_rate=0.05,    # Lower rate prevents overshooting\n",
    "    max_depth=8,           # Allows model to capture complex interactions\n",
    "    subsample=0.8,         # Uses 80% of data per tree to prevent overfitting\n",
    "    colsample_bytree=0.8,  # Uses 80% of features per tree\n",
    "    random_state=42\n",
    ")\n",
    "tab_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict and Convert back from Log-Scale\n",
    "y_pred_log = tab_model.predict(X_test)\n",
    "\n",
    "# Convert both back to actual dollars for the final report\n",
    "y_pred_dollars = np.expm1(y_pred_log)\n",
    "y_test_dollars = np.expm1(y_test)\n",
    "\n",
    "# 5. Calculate Metrics\n",
    "r2 = r2_score(y_test_dollars, y_pred_dollars)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_dollars, y_pred_dollars))\n",
    "\n",
    "print(f\"--- TABULAR ONLY PERFORMANCE ---\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: ${rmse:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "def generate_gradcam(model, img_tensor, tab_tensor):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Target the last convolutional layer in your vision branch \n",
    "    target_layer = model.vision_features[-1][-1].bn2 \n",
    "    \n",
    "    # 2. Hooks to capture gradients and activations\n",
    "    gradients = []\n",
    "    activations = []\n",
    "    def save_gradient(grad): gradients.append(grad)\n",
    "    def save_activation(module, input, output): activations.append(output)\n",
    "    \n",
    "    target_layer.register_forward_hook(save_activation)\n",
    "    \n",
    "    # 3. Forward pass\n",
    "    output = model(img_tensor.unsqueeze(0), tab_tensor.unsqueeze(0))\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # 4. Backward pass to get gradients\n",
    "    output.backward()\n",
    "    target_layer.weight.register_hook(save_gradient)\n",
    "    \n",
    "    # 5. Calculate weights and heatmap\n",
    "    weights = torch.mean(gradients[0], dim=(2, 3), keepdim=True)\n",
    "    cam = torch.sum(weights * activations[0], dim=1).squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    # 6. Normalize and resize\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "    return cam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
