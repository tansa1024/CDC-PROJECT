{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153289db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, tabular_input_dim):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        \n",
    "        # Branch 1: Image (ResNet18)\n",
    "        self.cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        cnn_out_features = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Identity() # Remove classification layer\n",
    "\n",
    "        # Branch 2: Tabular (Multilayer Perceptron)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(tabular_input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Fusion: Merge CNN (512) and MLP (64) outputs\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1) # Output: Predicted Log Price\n",
    "        )\n",
    "\n",
    "    def forward(self, image, tabular):\n",
    "        img_feats = self.cnn(image)\n",
    "        tab_feats = self.mlp(tabular)\n",
    "        combined = torch.cat((img_feats, tab_feats), dim=1)\n",
    "        return self.fusion(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fd4bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Initialize the Dataset using your processed CSV and images folder\n",
    "train_ds = MultimodalDataset(\"data/processed_train.csv\", \"house_images\", transform=transform)\n",
    "\n",
    "# 2. Define the train_loader (This fixes your NameError)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fce4ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # Load image via ID\n",
    "        img_path = os.path.join(self.img_dir, f\"{int(row['id'])}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Features and target\n",
    "        tabular = torch.tensor(row.drop(['id', 'price_log']).values, dtype=torch.float)\n",
    "        target = torch.tensor(row['price_log'], dtype=torch.float).unsqueeze(0)\n",
    "        \n",
    "        return image, tabular, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6981bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: 100%|██████████| 402/402 [01:40<00:00,  4.00it/s, loss=0.721] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete. Average Loss: 12.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: 100%|██████████| 402/402 [01:38<00:00,  4.07it/s, loss=0.564] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete. Average Loss: 0.1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]: 100%|██████████| 402/402 [01:27<00:00,  4.61it/s, loss=0.236] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete. Average Loss: 0.0739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: 100%|██████████| 402/402 [01:31<00:00,  4.39it/s, loss=0.383] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete. Average Loss: 0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]: 100%|██████████| 402/402 [01:31<00:00,  4.41it/s, loss=0.37]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete. Average Loss: 0.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]: 100%|██████████| 402/402 [01:27<00:00,  4.59it/s, loss=0.0358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 complete. Average Loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]: 100%|██████████| 402/402 [01:26<00:00,  4.63it/s, loss=0.00401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 complete. Average Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]: 100%|██████████| 402/402 [01:51<00:00,  3.59it/s, loss=0.117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 complete. Average Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]: 100%|██████████| 402/402 [01:25<00:00,  4.68it/s, loss=0.197] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 complete. Average Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]: 100%|██████████| 402/402 [01:28<00:00,  4.57it/s, loss=0.629] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 complete. Average Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]: 100%|██████████| 402/402 [01:28<00:00,  4.52it/s, loss=0.00106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 complete. Average Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]: 100%|██████████| 402/402 [01:16<00:00,  5.25it/s, loss=0.024] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 complete. Average Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]: 100%|██████████| 402/402 [01:18<00:00,  5.15it/s, loss=0.0687] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 complete. Average Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]: 100%|██████████| 402/402 [01:22<00:00,  4.87it/s, loss=0.115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 complete. Average Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]: 100%|██████████| 402/402 [01:22<00:00,  4.89it/s, loss=0.0105] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 complete. Average Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]: 100%|██████████| 402/402 [01:27<00:00,  4.60it/s, loss=0.0641] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 complete. Average Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]: 100%|██████████| 402/402 [01:25<00:00,  4.72it/s, loss=0.0924] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 complete. Average Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]: 100%|██████████| 402/402 [01:24<00:00,  4.78it/s, loss=0.00074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 complete. Average Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]: 100%|██████████| 402/402 [01:21<00:00,  4.93it/s, loss=0.128]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 complete. Average Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]: 100%|██████████| 402/402 [01:22<00:00,  4.85it/s, loss=0.00985]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 complete. Average Loss: 0.0273\n",
      "Model saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultiModalModel(tabular_input_dim=17).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Wrap train_loader with tqdm for a progress bar\n",
    "    loop = tqdm(train_loader, total=len(train_loader), leave=True)\n",
    "    loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "\n",
    "    for images, tabular, targets in loop:\n",
    "        images, tabular, targets = images.to(device), tabular.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, tabular)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} complete. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the weights\n",
    "torch.save(model.state_dict(), \"data/multimodal_model.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8be5471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 101/101 [00:59<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance ---\n",
      "RMSE: $168,006.53\n",
      "R² Score: 0.7587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 1. Prepare Test Loader\n",
    "test_ds = MultimodalDataset(\"data/processed_test.csv\", \"house_images\", transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# 2. Inference Loop\n",
    "with torch.no_grad():\n",
    "    for images, tabular, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images, tabular = images.to(device), tabular.to(device)\n",
    "        \n",
    "        outputs = model(images, tabular)\n",
    "        \n",
    "        # Move to CPU and store\n",
    "        all_preds.extend(outputs.cpu().numpy())\n",
    "        all_targets.extend(targets.numpy())\n",
    "\n",
    "# 3. Convert back from Log-Space to Real Prices\n",
    "# We use np.expm1 because we used np.log1p during preprocessing\n",
    "real_preds = np.expm1(all_preds)\n",
    "real_targets = np.expm1(all_targets)\n",
    "\n",
    "# 4. Calculate Metrics\n",
    "rmse = np.sqrt(mean_squared_error(real_targets, real_preds))\n",
    "r2 = r2_score(real_targets, real_preds)\n",
    "\n",
    "print(f\"\\n--- Model Performance ---\")\n",
    "print(f\"RMSE: ${rmse:,.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "def generate_gradcam(model, img_tensor, tab_tensor):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Target the last convolutional layer in your vision branch \n",
    "    target_layer = model.vision_features[-1][-1].bn2 \n",
    "    \n",
    "    # 2. Hooks to capture gradients and activations\n",
    "    gradients = []\n",
    "    activations = []\n",
    "    def save_gradient(grad): gradients.append(grad)\n",
    "    def save_activation(module, input, output): activations.append(output)\n",
    "    \n",
    "    target_layer.register_forward_hook(save_activation)\n",
    "    \n",
    "    # 3. Forward pass\n",
    "    output = model(img_tensor.unsqueeze(0), tab_tensor.unsqueeze(0))\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # 4. Backward pass to get gradients\n",
    "    output.backward()\n",
    "    target_layer.weight.register_hook(save_gradient)\n",
    "    \n",
    "    # 5. Calculate weights and heatmap\n",
    "    weights = torch.mean(gradients[0], dim=(2, 3), keepdim=True)\n",
    "    cam = torch.sum(weights * activations[0], dim=1).squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    # 6. Normalize and resize\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "    return cam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
