{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fed08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        # Handle both string paths and DataFrames\n",
    "        self.data = pd.read_csv(csv_file) if isinstance(csv_file, str) else csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tab_features = torch.tensor(row.drop(['id', 'price_log'], errors='ignore').values, dtype=torch.float32)\n",
    "        label = torch.tensor(row['price_log'], dtype=torch.float32)\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, f\"{int(row['id'])}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, tab_features, label\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # New: Helps generalization\n",
    "    transforms.RandomRotation(15),           # New: Handles satellite tilt\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247d8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, num_tabular_cols):\n",
    "        super(PricePredictor, self).__init__()\n",
    "        # 1. Change the model name\n",
    "        self.resnet = models.resnet50(weights='DEFAULT') \n",
    "        self.vision_features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.tabular_branch = nn.Sequential(\n",
    "            nn.Linear(num_tabular_cols, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(2048 + 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        v_feat = self.vision_features(img).view(img.size(0), -1)\n",
    "        t_feat = self.tabular_branch(tab)\n",
    "        combined = torch.cat((v_feat, t_feat), dim=1)\n",
    "        return self.regressor(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6981bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded. Model will use 13 tabular features.\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\tanis/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:26<00:00, 3.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to train on cpu!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Load the scaler and count features correctly\n",
    "scaler = joblib.load('data/scaler.pkl')\n",
    "num_features = len(scaler.feature_names_in_)\n",
    "print(f\"Scaler loaded. Model will use {num_features} tabular features.\")\n",
    "\n",
    "# 2. Setup DataLoaders\n",
    "train_dataset = MultimodalDataset('data/processed_train.csv', 'house_images', image_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 3. Initialize Model once\n",
    "model = PricePredictor(num_tabular_cols=num_features)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 4. Setup Optimizer and NEW Scheduler for better accuracy\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # Lower LR for stability\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "print(f\"Ready to train on {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b952b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 807/807 [13:07<00:00,  1.03it/s, loss=0.721]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Complete. Avg Loss: 8.1726 | LR: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 807/807 [09:31<00:00,  1.41it/s, loss=0.189] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Complete. Avg Loss: 0.2694 | LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 807/807 [11:17<00:00,  1.19it/s, loss=0.248]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Complete. Avg Loss: 0.1364 | LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 807/807 [14:08<00:00,  1.05s/it, loss=0.0625]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Complete. Avg Loss: 0.1121 | LR: 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 807/807 [10:37<00:00,  1.27it/s, loss=0.219] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Complete. Avg Loss: 0.0929 | LR: 2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 807/807 [11:16<00:00,  1.19it/s, loss=0.119] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Complete. Avg Loss: 0.0852 | LR: 1.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 807/807 [10:13<00:00,  1.32it/s, loss=0.0485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Complete. Avg Loss: 0.0769 | LR: 1.25e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 807/807 [09:12<00:00,  1.46it/s, loss=0.118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Complete. Avg Loss: 0.0736 | LR: 6.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 807/807 [09:30<00:00,  1.41it/s, loss=0.0512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Complete. Avg Loss: 0.0687 | LR: 6.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 807/807 [09:48<00:00,  1.37it/s, loss=0.069] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Complete. Avg Loss: 0.0669 | LR: 3.125e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Increase epochs to 10 for better accuracy if your time allows\n",
    "epochs = 10 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Progress bar setup\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
    "    \n",
    "    for images, tabular, labels in loop:\n",
    "        # Move data to GPU/CPU\n",
    "        images, tabular, labels = images.to(device), tabular.to(device), labels.to(device).view(-1, 1)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, tabular)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass & Optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar with live loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # Update the Learning Rate\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Complete. Avg Loss: {avg_loss:.4f} | LR: {current_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb71179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loader ready with 3229 houses!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the processed test data created in the Preprocessing Notebook\n",
    "test_df = pd.read_csv('data/processed_test.csv')\n",
    "\n",
    "# 2. Create the Test Dataset object\n",
    "test_dataset = MultimodalDataset(\n",
    "    csv_file=test_df, \n",
    "    img_dir='house_images', \n",
    "    transform=image_transforms\n",
    ")\n",
    "\n",
    "# 3. Create the Test Loader\n",
    "# We use shuffle=False because we want the results in a predictable order\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Test Loader ready with {len(test_df)} houses!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "846b2e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 202/202 [01:21<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables all_preds and all_actuals are now defined!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval() # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_actuals = []\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculation to save memory\n",
    "    for images, tabular, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images, tabular = images.to(device), tabular.to(device)\n",
    "        \n",
    "        # Get model output\n",
    "        outputs = model(images, tabular)\n",
    "        \n",
    "        # Convert log-prices back to actual dollars\n",
    "        all_preds.extend(np.expm1(outputs.cpu().numpy()).flatten())\n",
    "        all_actuals.extend(np.expm1(labels.numpy()).flatten())\n",
    "\n",
    "print(\"Variables all_preds and all_actuals are now defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a91a383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL MODEL PERFORMANCE ---\n",
      "R2 Score: 0.6955\n",
      "Mean Absolute Error (MAE): $114,119.39\n",
      "Root Mean Squared Error (RMSE): $186,368.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 1. Convert lists to numpy arrays\n",
    "preds_array = np.array(all_preds)\n",
    "actuals_array = np.array(all_actuals)\n",
    "\n",
    "# 2. Calculate R2 Score (Accuracy)\n",
    "r2 = r2_score(actuals_array, preds_array)\n",
    "\n",
    "# 3. Calculate MAE (Average Error)\n",
    "mae = np.mean(np.abs(preds_array - actuals_array))\n",
    "\n",
    "# 4. Calculate RMSE (Penalty for large errors)\n",
    "rmse = np.sqrt(mean_squared_error(actuals_array, preds_array))\n",
    "\n",
    "print(f\"--- FINAL MODEL PERFORMANCE ---\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): ${rmse:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e365135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the weights to a file\n",
    "torch.save(model.state_dict(), 'multimodal_house_model_v1.pth')\n",
    "print(\"Model weights saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
